@article{delobelle2021ethical,
author = {Delobelle, Pieter and Temple, Paul and Perrouin, Gilles and Fr\'{e}nay, Benoit and Heymans, Patrick and Berendt, Bettina},
title = {Ethical Adversaries: Towards Mitigating Unfairness with Adversarial Machine Learning},
year = {2021},
issue_date = {June 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {1},
issn = {1931-0145},
url = {https://doi.org/10.1145/3468507.3468513},
doi = {10.1145/3468507.3468513},
abstract = {Machine learning is being integrated into a growing number of critical systems with far-reaching impacts on society. Unexpected behaviour and unfair decision processes are coming under increasing scrutiny due to this widespread use and its theoretical considerations. Individuals, as well as organisations, notice, test, and criticize unfair results to hold model designers and deployers accountable. We offer a framework that assists these groups in mitigating unfair representations stemming from the training datasets. Our framework relies on two inter-operating adversaries to improve fairness. First, a model is trained with the goal of preventing the guessing of protected attributes' values while limiting utility losses. This first step optimizes the model's parameters for fairness. Second, the framework leverages evasion attacks from adversarial machine learning to generate new examples that will be misclassified. These new examples are then used to retrain and improve the model in the first step. These two steps are iteratively applied until a significant improvement in fairness is obtained. We evaluated our framework on well-studied datasets in the fairness literature - including COMPAS - where it can surpass other approaches concerning demographic parity, equality of opportunity and also the model's utility. We investigated the trade-offs between these targets in terms of model hyperparameters and also illustrated our findings on the subtle difficulties when mitigating unfairness and highlight how our framework can assist model designers.},
journal = {SIGKDD Explor. Newsl.},
month = {may},
pages = {32â€“41},
numpages = {10},
keywords = {fairness, adversarial machine learning, neural networks}
}