{
    "post_title": "Tik-to-Tok",
    "post_subtitle": "Translating language models one token at a time",
    "abstract": "Training monolingual language models for low and mid-resource languages is made challenging by limited and often inadequate pretraining data. We propose a novel model conversion strategy to address this issue, adapting high-resources monolingual language models to a new target language. We map tokens from the target tokenizer to semantically similar tokens from the source language tokenizer.",
    "type": "md",
    "post_tag": "paper",
    "banner": true,
    "theme": "dark",
    "img": "untitled-1.png",
    "author": "Fran√ßois Remy, Pieter Delobelle, Bettina Berendt, Kris Demuynck, Thomas Demeester",
    "date": "2023-10-19",
    "background": "linear-gradient(139deg, rgba(220,240,255,1) 0%, rgba(189,224,251,1) 100%)",
    "pdf": "https://arxiv.org/pdf/2310.03477.pdf",
    "bibtex": "",
    "absoluteresource": "",
    "draft": false,
    "code": "",
    "featured": true,
    "project": true,
    "blog": false,
    "related_work": [],
    "video": ""

  }
  